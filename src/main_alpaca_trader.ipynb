{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc5a792",
   "metadata": {},
   "source": [
    "# Alpaca Paper Trading â€” Mean Reversion Strategy\n",
    "\n",
    "**Three operating modes:**\n",
    "1. **Replay Mode** â€” Replay historical data day-by-day through the live pipeline. Validates that live system matches backtest results.\n",
    "2. **Shadow Mode** â€” Run on live Alpaca data but don't submit orders. Track hypothetical P&L. Build confidence before going live.\n",
    "3. **Live Mode** â€” Submit real paper-trade orders to Alpaca.\n",
    "\n",
    "**Workflow:**\n",
    "- Cell 1â€“3: Setup, connection, universe selection\n",
    "- Cell 4â€“5: Data fetch + signal generation (shared by all modes)\n",
    "- Cell 6: **Replay** â€” historical validation\n",
    "- Cell 7â€“8: **Shadow / Live** â€” daily trading workflow\n",
    "- Cell 9: Position monitoring & trade log export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a39873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import sys, os, time, logging, importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure src/ is on the path\n",
    "src_dir = Path.cwd() if Path.cwd().name == 'src' else Path.cwd() / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# â”€â”€â”€ Existing strategy modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from strategy_config import ConfigLoader\n",
    "from strategies.mean_reversion import MeanReversionSignals, SignalConfig\n",
    "from backtest.engine import BacktestEngine, BacktestConfig\n",
    "\n",
    "# â”€â”€â”€ New Alpaca modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from connection.alpaca_connection import AlpacaConfig, AlpacaConnection, TradingMode\n",
    "from data.alpaca_data import AlpacaDataAdapter\n",
    "from execution.alpaca_executor import AlpacaExecutor, TradeDecision, TradeResult\n",
    "from execution.simulation import SimulationEngine\n",
    "\n",
    "# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ Load config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "config = ConfigLoader()\n",
    "signal_config = config.to_signal_config()\n",
    "bt_config = config.to_backtest_config()\n",
    "composite_weights = config.get_composite_weights()\n",
    "\n",
    "print(\"âœ… All modules loaded\")\n",
    "print(f\"   Signal mode: {signal_config.signal_mode}\")\n",
    "print(f\"   Kalman: {'ON' if signal_config.use_kalman else 'OFF'}\")\n",
    "print(f\"   OU Gate: {'ON' if signal_config.use_predicted_return else 'OFF'}\")\n",
    "print(f\"   Entry threshold: {bt_config.entry_threshold}\")\n",
    "print(f\"   Exit threshold:  {bt_config.exit_threshold}\")\n",
    "print(f\"   Stop loss: {bt_config.stop_loss_pct}\")\n",
    "print(f\"   Max hold:  {bt_config.max_holding_days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96201f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 2: CONNECT TO ALPACA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Set trading mode here:\n",
    "#   TradingMode.REPLAY  â€” historical replay (no API calls for orders)\n",
    "#   TradingMode.SHADOW  â€” live data, simulated trades\n",
    "#   TradingMode.LIVE    â€” submit real paper-trade orders\n",
    "\n",
    "TRADING_MODE = TradingMode.SHADOW  # â† Change this as needed\n",
    "\n",
    "# Load API keys from .env and create connection\n",
    "alpaca_config = AlpacaConfig.from_env()\n",
    "alpaca_config.trading_mode = TRADING_MODE\n",
    "\n",
    "conn = AlpacaConnection(alpaca_config)\n",
    "conn.test_connection()\n",
    "\n",
    "print(f\"\\nðŸ”§ Trading mode: {TRADING_MODE.value.upper()}\")\n",
    "if TRADING_MODE == TradingMode.REPLAY:\n",
    "    print(\"   â†’ Using historical data only. No Alpaca API orders.\")\n",
    "elif TRADING_MODE == TradingMode.SHADOW:\n",
    "    print(\"   â†’ Live data, simulated trades. No real orders submitted.\")\n",
    "else:\n",
    "    print(\"   â†’ âš ï¸  LIVE MODE: Real paper-trade orders will be submitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 3: SELECT TOP-30 UNIVERSE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Alpaca free tier: max 30 websocket symbols.\n",
    "# We pick the 30 best mean-reverters from our 216-symbol universe.\n",
    "# Criteria: lowest Hurst exponent â†’ strongest mean reversion.\n",
    "\n",
    "from data.universe_builder import SP500_CORE, NASDAQ_100_CORE, DOW_30, RUSSELL_2000_CORE\n",
    "\n",
    "# Combine all curated symbols (unique)\n",
    "all_symbols = sorted(set(SP500_CORE + NASDAQ_100_CORE + DOW_30 + RUSSELL_2000_CORE))\n",
    "print(f\"Total curated universe: {len(all_symbols)} symbols\")\n",
    "\n",
    "# â”€â”€ Option A: Use cached Hurst data from backtest (fast) â”€â”€\n",
    "# If you've already run the backtest notebook, load the parquet snapshots\n",
    "hurst_cache = Path('../data/snapshots/hurst_rankings.csv')\n",
    "if hurst_cache.exists():\n",
    "    hurst_df = pd.read_csv(hurst_cache)\n",
    "    top30 = hurst_df.nsmallest(30, 'hurst_exponent')['symbol'].tolist()\n",
    "    print(f\"Loaded cached Hurst rankings â†’ top 30 selected\")\n",
    "else:\n",
    "    # â”€â”€ Option B: Compute Hurst from locally cached historical data â”€â”€\n",
    "    daily_dir = Path('../data/historical/daily')\n",
    "    if daily_dir.exists() and list(daily_dir.glob('*.parquet')):\n",
    "        print(\"Computing Hurst exponents from local data...\")\n",
    "        signal_gen = MeanReversionSignals(signal_config)\n",
    "        hurst_results = {}\n",
    "\n",
    "        for pf in sorted(daily_dir.glob('*.parquet')):\n",
    "            sym = pf.stem\n",
    "            try:\n",
    "                df = pd.read_parquet(pf)\n",
    "                prices = df['close'] if 'close' in df.columns else df.iloc[:, 0]\n",
    "                if len(prices) >= 100:\n",
    "                    h = signal_gen.calculate_hurst_exponent(prices)\n",
    "                    if h is not None and h < 0.5:\n",
    "                        hurst_results[sym] = h\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if hurst_results:\n",
    "            ranked = sorted(hurst_results.items(), key=lambda x: x[1])\n",
    "            top30 = [s for s, _ in ranked[:30]]\n",
    "            print(f\"Computed Hurst for {len(hurst_results)} mean-reverting symbols\")\n",
    "        else:\n",
    "            # Fallback: diversified default selection\n",
    "            top30 = DOW_30[:30]\n",
    "            print(\"âš ï¸  No Hurst data available â€” falling back to DOW 30\")\n",
    "    else:\n",
    "        top30 = DOW_30[:30]\n",
    "        print(\"âš ï¸  No local data â€” falling back to DOW 30\")\n",
    "\n",
    "UNIVERSE = top30\n",
    "print(f\"\\nðŸ“Š Trading Universe ({len(UNIVERSE)} symbols):\")\n",
    "for i in range(0, len(UNIVERSE), 10):\n",
    "    print(f\"   {', '.join(UNIVERSE[i:i+10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 4: FETCH DATA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Pulls daily bars from Alpaca (IEX) and converts to our pipeline format.\n",
    "# For REPLAY mode, fetches the full historical window.\n",
    "# For SHADOW/LIVE mode, fetches lookback + warmup for signal generation.\n",
    "\n",
    "LOOKBACK_DAYS = 504  # 2 years for signal warmup (matches backtest train window)\n",
    "\n",
    "adapter = AlpacaDataAdapter(\n",
    "    data_client=conn.data_client,\n",
    "    data_feed=alpaca_config.data_feed,\n",
    "    cache_dir=Path('../data/snapshots/alpaca_cache'),\n",
    ")\n",
    "\n",
    "print(f\"Fetching {LOOKBACK_DAYS} days of daily bars for {len(UNIVERSE)} symbols...\")\n",
    "print(f\"Data feed: {alpaca_config.data_feed.upper()}\\n\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "price_df, volume_df, raw_bars = adapter.fetch_pipeline_data(\n",
    "    symbols=UNIVERSE,\n",
    "    lookback_days=LOOKBACK_DAYS,\n",
    ")\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "print(f\"\\nâœ… Data fetched in {elapsed:.1f}s\")\n",
    "print(f\"   Date range: {price_df.index.min().date()} â†’ {price_df.index.max().date()}\")\n",
    "print(f\"   Trading days: {len(price_df)}\")\n",
    "print(f\"   Symbols with data: {len(price_df.columns)}\")\n",
    "print(f\"   Missing symbols: {set(UNIVERSE) - set(price_df.columns)}\")\n",
    "\n",
    "# Update universe to only symbols with valid data\n",
    "UNIVERSE = list(price_df.columns)\n",
    "\n",
    "# Cache for offline use\n",
    "adapter.save_cache(price_df, volume_df, tag='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 5: GENERATE SIGNALS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Same signal pipeline as the backtest notebook.\n",
    "# Generates composite + individual signals for all symbols.\n",
    "\n",
    "signal_gen = MeanReversionSignals(signal_config)\n",
    "\n",
    "print(f\"Generating signals for {len(UNIVERSE)} symbols...\")\n",
    "print(f\"  Weights: {composite_weights}\")\n",
    "print(f\"  Mode: {signal_config.signal_mode} | Gate: {signal_config.gate_signal}\\n\")\n",
    "\n",
    "all_signals = {}\n",
    "all_individual_signals = {}\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "for i, symbol in enumerate(UNIVERSE):\n",
    "    if symbol in price_df.columns and symbol in volume_df.columns:\n",
    "        prices = price_df[symbol].dropna()\n",
    "        volumes = volume_df[symbol].dropna()\n",
    "\n",
    "        if len(prices) < 100:\n",
    "            continue\n",
    "\n",
    "        composite, individual = signal_gen.generate_composite_signal(\n",
    "            prices, volumes, weights=composite_weights\n",
    "        )\n",
    "        all_signals[symbol] = composite\n",
    "        all_individual_signals[symbol] = individual\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(UNIVERSE)}...\")\n",
    "\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"\\nâœ… Signals generated for {len(all_signals)} symbols in {elapsed:.1f}s\")\n",
    "\n",
    "# Build DataFrames matching backtest format\n",
    "signal_df = pd.DataFrame(all_signals)\n",
    "zscore_df = pd.DataFrame({\n",
    "    symbol: sigs['zscore']\n",
    "    for symbol, sigs in all_individual_signals.items()\n",
    "    if 'zscore' in sigs\n",
    "})\n",
    "\n",
    "# Align all data to common index\n",
    "common_idx = price_df.index.intersection(signal_df.index)\n",
    "price_df = price_df.loc[common_idx, signal_df.columns]\n",
    "volume_df = volume_df.loc[common_idx, signal_df.columns]\n",
    "signal_df = signal_df.loc[common_idx]\n",
    "zscore_df = zscore_df.loc[common_idx]\n",
    "\n",
    "# Show today's signals snapshot\n",
    "latest_date = signal_df.index[-1]\n",
    "latest_signals = signal_df.loc[latest_date].dropna().sort_values()\n",
    "print(f\"\\nðŸ“¡ Latest signals ({latest_date.date()}):\")\n",
    "print(f\"   Strong longs  (signal < -{bt_config.entry_threshold}): \"\n",
    "      f\"{(latest_signals < -bt_config.entry_threshold).sum()}\")\n",
    "print(f\"   Strong shorts (signal > +{bt_config.entry_threshold}): \"\n",
    "      f\"{(latest_signals > bt_config.entry_threshold).sum()}\")\n",
    "print(f\"   Signal range: [{latest_signals.min():.2f}, {latest_signals.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f529b",
   "metadata": {},
   "source": [
    "## Mode A: Historical Replay\n",
    "\n",
    "Replays historical data day-by-day through the live pipeline. Validates that the live execution system produces the same signals and trades as the backtest engine. Run this once before trusting the live system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96867bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 6: HISTORICAL REPLAY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Replays the full signal_df day-by-day through the execution pipeline.\n",
    "# Compares results against the backtest engine to validate consistency.\n",
    "\n",
    "# Create executor in REPLAY mode\n",
    "replay_config = AlpacaConfig.from_env()\n",
    "replay_config.trading_mode = TradingMode.REPLAY\n",
    "replay_conn = AlpacaConnection(replay_config)\n",
    "\n",
    "replay_executor = AlpacaExecutor(\n",
    "    connection=replay_conn,\n",
    "    commission_pct=bt_config.commission_pct,\n",
    "    max_position_pct=bt_config.max_position_size,\n",
    "    max_total_exposure=bt_config.max_total_exposure,\n",
    ")\n",
    "\n",
    "sim = SimulationEngine(\n",
    "    executor=replay_executor,\n",
    "    initial_capital=bt_config.initial_capital,\n",
    "    commission_pct=bt_config.commission_pct,\n",
    "    slippage_pct=bt_config.slippage_pct,\n",
    ")\n",
    "\n",
    "# Run replay over the data range\n",
    "# Use last N years for meaningful comparison (skip warmup period)\n",
    "REPLAY_YEARS = 2  # â† Change to test different windows\n",
    "replay_start = signal_df.index[-1] - pd.DateOffset(years=REPLAY_YEARS)\n",
    "replay_start = signal_df.index[signal_df.index >= replay_start][0]\n",
    "\n",
    "print(f\"ðŸ”„ Running replay: {replay_start.date()} â†’ {signal_df.index[-1].date()}\")\n",
    "print(f\"   Capital: ${bt_config.initial_capital:,.0f}\")\n",
    "print(f\"   Commission: {bt_config.commission_pct:.2%} | Slippage: {bt_config.slippage_pct:.2%}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "replay_results = sim.run_replay(\n",
    "    price_df=price_df,\n",
    "    signal_df=signal_df,\n",
    "    volume_df=volume_df,\n",
    "    exit_signal_df=zscore_df,\n",
    "    config=bt_config,\n",
    "    start_date=replay_start,\n",
    "    end_date=signal_df.index[-1],\n",
    "    verbose=True,\n",
    ")\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"\\nâ±ï¸  Replay completed in {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 7: REPLAY vs BACKTEST COMPARISON\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Run the same period through BacktestEngine for comparison.\n",
    "\n",
    "print(\"Running backtest on same period for comparison...\")\n",
    "\n",
    "bt_engine = BacktestEngine(bt_config)\n",
    "bt_results = bt_engine.run_backtest(\n",
    "    price_df.loc[replay_start:],\n",
    "    signal_df.loc[replay_start:],\n",
    "    volume_df.loc[replay_start:],\n",
    "    exit_signal_data=zscore_df.loc[replay_start:],\n",
    ")\n",
    "\n",
    "print(f\"  Backtest: {bt_results.summary()['total_return']}\")\n",
    "\n",
    "# Compare equity curves\n",
    "replay_equity = replay_results['equity_curve']\n",
    "bt_equity = bt_results.equity_curve\n",
    "\n",
    "comparison = sim.compare_with_backtest(\n",
    "    backtest_equity=bt_equity,\n",
    "    label_sim='Replay (Live Pipeline)',\n",
    "    label_bt='Backtest Engine',\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Comparison Metrics:\")\n",
    "print(f\"   Correlation:     {comparison['correlation']:.4f}\")\n",
    "print(f\"   Tracking Error:  {comparison['tracking_error_pct']:.2f}%\")\n",
    "print(f\"   Max Deviation:   {comparison['max_deviation']:.2f}%\")\n",
    "print(f\"   Avg Deviation:   {comparison['avg_deviation']:.2f}%\")\n",
    "\n",
    "if comparison['correlation'] > 0.95:\n",
    "    print(\"\\nâœ… Strong match! Live pipeline is consistent with backtest.\")\n",
    "elif comparison['correlation'] > 0.85:\n",
    "    print(\"\\nâš ï¸  Moderate match. Check for timing/sizing differences.\")\n",
    "else:\n",
    "    print(\"\\nâŒ Significant divergence â€” investigate before going live.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2720ff",
   "metadata": {},
   "source": [
    "## Mode B: Shadow / Live Daily Trading\n",
    "\n",
    "Run this section daily. In **Shadow mode**, it generates signals and tracks hypothetical trades without submitting orders. In **Live mode**, it submits real paper-trade orders to Alpaca.\n",
    "\n",
    "**Daily workflow:** Run cells 1â€“5 (setup + data + signals), then cell 8 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caca18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 8: DAILY SHADOW / LIVE EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Processes today's signals through the execution pipeline.\n",
    "# In SHADOW mode: logs hypothetical trades, tracks simulated P&L.\n",
    "# In LIVE mode: submits real orders to Alpaca paper trading.\n",
    "#\n",
    "# State persistence: shadow positions survive across runs via trade log CSV.\n",
    "\n",
    "# â”€â”€â”€ Initialize or restore shadow state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SHADOW_LOG = Path('../data/snapshots/shadow_state.csv')\n",
    "\n",
    "executor = AlpacaExecutor(\n",
    "    connection=conn,\n",
    "    commission_pct=0.0 if TRADING_MODE == TradingMode.LIVE else bt_config.commission_pct,\n",
    "    max_position_pct=bt_config.max_position_size,\n",
    "    max_total_exposure=bt_config.max_total_exposure,\n",
    ")\n",
    "\n",
    "shadow_sim = SimulationEngine(\n",
    "    executor=executor,\n",
    "    initial_capital=bt_config.initial_capital,\n",
    "    commission_pct=bt_config.commission_pct if TRADING_MODE != TradingMode.LIVE else 0.0,\n",
    "    slippage_pct=bt_config.slippage_pct if TRADING_MODE != TradingMode.LIVE else 0.0,\n",
    ")\n",
    "\n",
    "# Restore previous shadow positions if they exist\n",
    "if SHADOW_LOG.exists() and TRADING_MODE == TradingMode.SHADOW:\n",
    "    prev = pd.read_csv(SHADOW_LOG)\n",
    "    if not prev.empty:\n",
    "        for _, row in prev.iterrows():\n",
    "            from execution.simulation import SimulatedPosition\n",
    "            shadow_sim.positions[row['symbol']] = SimulatedPosition(\n",
    "                symbol=row['symbol'],\n",
    "                qty=int(row['qty']),\n",
    "                side=row['side'],\n",
    "                entry_price=float(row['entry_price']),\n",
    "                entry_date=pd.Timestamp(row['entry_date']),\n",
    "                signal_strength=float(row.get('signal_strength', 0)),\n",
    "                current_price=float(row.get('current_price', row['entry_price'])),\n",
    "            )\n",
    "        shadow_sim.cash -= sum(\n",
    "            p.entry_price * abs(p.qty) for p in shadow_sim.positions.values()\n",
    "            if p.side == 'long'\n",
    "        )\n",
    "        print(f\"â™»ï¸  Restored {len(shadow_sim.positions)} shadow positions\")\n",
    "\n",
    "# â”€â”€â”€ Process today â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "today = signal_df.index[-1]  # Latest date with signals\n",
    "print(f\"\\n{'â•'*60}\")\n",
    "print(f\"  DAILY EXECUTION â€” {today.date()} â€” {TRADING_MODE.value.upper()} MODE\")\n",
    "print(f\"{'â•'*60}\")\n",
    "\n",
    "if TRADING_MODE in (TradingMode.SHADOW, TradingMode.REPLAY):\n",
    "    # Shadow: process through simulation engine\n",
    "    shadow_sim.process_shadow_day(\n",
    "        date=today,\n",
    "        signal_df=signal_df,\n",
    "        price_df=price_df,\n",
    "        volume_df=volume_df,\n",
    "        exit_signal_df=zscore_df,\n",
    "        config=bt_config,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Save shadow state for next run\n",
    "    if shadow_sim.positions:\n",
    "        state_rows = []\n",
    "        for sym, pos in shadow_sim.positions.items():\n",
    "            state_rows.append({\n",
    "                'symbol': pos.symbol, 'qty': pos.qty, 'side': pos.side,\n",
    "                'entry_price': pos.entry_price, 'entry_date': pos.entry_date,\n",
    "                'signal_strength': pos.signal_strength,\n",
    "                'current_price': pos.current_price,\n",
    "            })\n",
    "        pd.DataFrame(state_rows).to_csv(SHADOW_LOG, index=False)\n",
    "        print(f\"\\nðŸ’¾ Shadow state saved ({len(state_rows)} positions)\")\n",
    "    else:\n",
    "        if SHADOW_LOG.exists():\n",
    "            SHADOW_LOG.unlink()\n",
    "        print(\"\\nðŸ’¾ No open positions â€” shadow state cleared\")\n",
    "\n",
    "else:\n",
    "    # LIVE mode: generate decisions and submit orders\n",
    "    current_positions = {}\n",
    "    for pos in conn.get_positions():\n",
    "        current_positions[pos['symbol']] = {\n",
    "            'qty': int(pos['qty']),\n",
    "            'side': 'long' if int(pos['qty']) > 0 else 'short',\n",
    "            'entry_price': float(pos['avg_entry_price']),\n",
    "            'entry_date': pd.Timestamp.now() - pd.Timedelta(days=1),  # Approximate\n",
    "        }\n",
    "\n",
    "    decisions = executor.generate_decisions_from_signals(\n",
    "        signal_df=signal_df,\n",
    "        price_df=price_df,\n",
    "        volume_df=volume_df,\n",
    "        exit_signal_df=zscore_df,\n",
    "        date=today,\n",
    "        current_positions=current_positions,\n",
    "        config=bt_config,\n",
    "    )\n",
    "\n",
    "    if decisions:\n",
    "        print(f\"\\nðŸ“‹ {len(decisions)} trade decisions:\")\n",
    "        for d in decisions:\n",
    "            print(f\"   {d.action.upper():6s} {d.symbol:6s} x{d.target_qty:4d}  \"\n",
    "                  f\"signal={d.signal_strength:+.3f}  {d.reason}\")\n",
    "\n",
    "        # Get current prices for execution\n",
    "        current_prices = adapter.get_latest_prices([d.symbol for d in decisions])\n",
    "        results = executor.execute_decisions(decisions, current_prices)\n",
    "\n",
    "        print(f\"\\nðŸ“Š Execution results:\")\n",
    "        for r in results:\n",
    "            status_icon = 'âœ…' if r.status in ('filled', 'submitted') else 'âŒ'\n",
    "            print(f\"   {status_icon} {r.decision.symbol} â†’ {r.status} \"\n",
    "                  f\"@ ${r.filled_price or 0:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nðŸ˜´ No trade signals today\")\n",
    "\n",
    "    # Show account summary\n",
    "    account = conn.get_account()\n",
    "    print(f\"\\nðŸ’° Account: ${account['portfolio_value']:,.2f} \"\n",
    "          f\"(cash: ${account['cash']:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d378c",
   "metadata": {},
   "source": [
    "## Monitoring & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 9: POSITION MONITORING DASHBOARD\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Shows current positions, P&L, and signal status across all modes.\n",
    "\n",
    "def show_dashboard(sim_engine=None, connection=None, mode=None):\n",
    "    \"\"\"Display position monitoring dashboard\"\"\"\n",
    "    print(f\"\\n{'â•'*70}\")\n",
    "    print(f\"  POSITION DASHBOARD â€” {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"{'â•'*70}\")\n",
    "\n",
    "    if mode in (TradingMode.SHADOW, TradingMode.REPLAY) and sim_engine:\n",
    "        # Shadow/Replay positions\n",
    "        print(f\"\\n  Mode: {mode.value.upper()} | Equity: ${sim_engine.equity:,.2f} \"\n",
    "              f\"| Cash: ${sim_engine.cash:,.2f}\")\n",
    "        print(f\"  Open positions: {len(sim_engine.positions)}\")\n",
    "        print(f\"  Completed trades: {len(sim_engine.completed_trades)}\")\n",
    "\n",
    "        if sim_engine.positions:\n",
    "            print(f\"\\n  {'Symbol':8s} {'Side':6s} {'Qty':>6s} {'Entry':>10s} \"\n",
    "                  f\"{'Current':>10s} {'P&L':>10s} {'P&L%':>8s} {'Days':>5s}\")\n",
    "            print(f\"  {'â”€'*65}\")\n",
    "\n",
    "            total_pnl = 0\n",
    "            for sym, pos in sorted(sim_engine.positions.items()):\n",
    "                days = (pd.Timestamp.now() - pos.entry_date).days\n",
    "                pnl = pos.unrealized_pnl\n",
    "                pnl_pct = pos.unrealized_pnl_pct * 100\n",
    "                total_pnl += pnl\n",
    "                icon = 'ðŸŸ¢' if pnl >= 0 else 'ðŸ”´'\n",
    "                print(f\"  {icon} {sym:6s} {pos.side:6s} {abs(pos.qty):6d} \"\n",
    "                      f\"${pos.entry_price:9.2f} ${pos.current_price:9.2f} \"\n",
    "                      f\"${pnl:9.2f} {pnl_pct:+7.2f}% {days:5d}\")\n",
    "            print(f\"  {'â”€'*65}\")\n",
    "            print(f\"  {'Total':55s} ${total_pnl:9.2f}\")\n",
    "\n",
    "        # Trade history summary\n",
    "        if sim_engine.completed_trades:\n",
    "            wins = sum(1 for t in sim_engine.completed_trades if t.pnl > 0)\n",
    "            losses = len(sim_engine.completed_trades) - wins\n",
    "            avg_pnl = np.mean([t.pnl_pct * 100 for t in sim_engine.completed_trades])\n",
    "            print(f\"\\n  Trade History: {wins}W / {losses}L | \"\n",
    "                  f\"Win rate: {wins/(wins+losses)*100:.1f}% | \"\n",
    "                  f\"Avg P&L: {avg_pnl:+.2f}%\")\n",
    "\n",
    "    elif mode == TradingMode.LIVE and connection:\n",
    "        # Live positions from Alpaca\n",
    "        account = connection.get_account()\n",
    "        positions = connection.get_positions()\n",
    "\n",
    "        print(f\"\\n  Equity: ${account['portfolio_value']:,.2f} | \"\n",
    "              f\"Cash: ${account['cash']:,.2f} | \"\n",
    "              f\"Day trades: {account['daytrade_count']}/3\")\n",
    "\n",
    "        if positions:\n",
    "            print(f\"\\n  {'Symbol':8s} {'Side':6s} {'Qty':>6s} {'Entry':>10s} \"\n",
    "                  f\"{'Current':>10s} {'P&L':>10s} {'P&L%':>8s}\")\n",
    "            print(f\"  {'â”€'*60}\")\n",
    "\n",
    "            for pos in positions:\n",
    "                qty = int(pos['qty'])\n",
    "                side = 'long' if qty > 0 else 'short'\n",
    "                entry = float(pos['avg_entry_price'])\n",
    "                current = float(pos['current_price'])\n",
    "                pnl = float(pos['unrealized_pl'])\n",
    "                pnl_pct = float(pos['unrealized_plpc']) * 100\n",
    "                icon = 'ðŸŸ¢' if pnl >= 0 else 'ðŸ”´'\n",
    "                print(f\"  {icon} {pos['symbol']:6s} {side:6s} {abs(qty):6d} \"\n",
    "                      f\"${entry:9.2f} ${current:9.2f} ${pnl:9.2f} {pnl_pct:+7.2f}%\")\n",
    "        else:\n",
    "            print(\"\\n  No open positions\")\n",
    "\n",
    "    # Show today's signals that hit thresholds\n",
    "    if 'signal_df' in dir() or 'signal_df' in globals():\n",
    "        latest = signal_df.iloc[-1].dropna()\n",
    "        entries = latest[latest.abs() > bt_config.entry_threshold].sort_values()\n",
    "        if len(entries) > 0:\n",
    "            print(f\"\\n  ðŸ“¡ Active entry signals ({len(entries)}):\")\n",
    "            for sym, val in entries.items():\n",
    "                direction = \"SHORT\" if val > 0 else \"LONG \"\n",
    "                print(f\"     {direction} {sym:6s}  signal={val:+.3f}\")\n",
    "\n",
    "\n",
    "# Run dashboard for the active mode\n",
    "active_sim = shadow_sim if 'shadow_sim' in dir() else (sim if 'sim' in dir() else None)\n",
    "show_dashboard(sim_engine=active_sim, connection=conn, mode=TRADING_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea10ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 10: EXPORT TRADE LOGS & EQUITY CURVES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "export_dir = Path('../data/snapshots/trading_logs')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# Export from whichever sim engine is active\n",
    "active = shadow_sim if 'shadow_sim' in dir() else (sim if 'sim' in dir() else None)\n",
    "\n",
    "if active and active.completed_trades:\n",
    "    trade_path = export_dir / f'trades_{TRADING_MODE.value}_{timestamp}.csv'\n",
    "    active.export_trade_log(trade_path)\n",
    "    print(f\"ðŸ“„ Trade log: {trade_path}\")\n",
    "\n",
    "if active and active.daily_snapshots:\n",
    "    equity_path = export_dir / f'equity_{TRADING_MODE.value}_{timestamp}.csv'\n",
    "    active.export_equity_curve(equity_path)\n",
    "    print(f\"ðŸ“ˆ Equity curve: {equity_path}\")\n",
    "\n",
    "    # Plot equity curve\n",
    "    snapshots_df = pd.DataFrame([\n",
    "        {'date': s.date, 'equity': s.equity, 'daily_pnl': s.daily_pnl,\n",
    "         'n_positions': s.n_positions, 'trades_entered': s.trades_entered,\n",
    "         'trades_exited': s.trades_exited}\n",
    "        for s in active.daily_snapshots\n",
    "    ])\n",
    "    snapshots_df.set_index('date', inplace=True)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "    # Equity\n",
    "    axes[0].plot(snapshots_df['equity'], linewidth=2, color='blue')\n",
    "    axes[0].set_ylabel('Equity ($)')\n",
    "    axes[0].set_title(f'Equity Curve â€” {TRADING_MODE.value.upper()} Mode')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    # Daily P&L\n",
    "    colors = ['green' if x >= 0 else 'red' for x in snapshots_df['daily_pnl']]\n",
    "    axes[1].bar(snapshots_df.index, snapshots_df['daily_pnl'], color=colors, alpha=0.7)\n",
    "    axes[1].set_ylabel('Daily P&L ($)')\n",
    "    axes[1].set_title('Daily P&L')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    # Position count\n",
    "    axes[2].fill_between(snapshots_df.index, 0, snapshots_df['n_positions'],\n",
    "                         alpha=0.5, color='purple')\n",
    "    axes[2].set_ylabel('Positions')\n",
    "    axes[2].set_title('Open Positions')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No trading data to export yet. Run replay or shadow mode first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

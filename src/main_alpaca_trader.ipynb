{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc5a792",
   "metadata": {},
   "source": [
    "# Alpaca Paper Trading â€” Mean Reversion Strategy\n",
    "\n",
    "**Three operating modes:**\n",
    "1. **Replay Mode** â€” Replay historical data day-by-day through the live pipeline. Validates that live system matches backtest results.\n",
    "2. **Shadow Mode** â€” Run on live Alpaca data but don't submit orders. Track hypothetical P&L. Build confidence before going live.\n",
    "3. **Live Mode** â€” Submit real paper-trade orders to Alpaca.\n",
    "\n",
    "**Workflow:**\n",
    "- Cell 1â€“3: Setup, connection, universe selection\n",
    "- Cell 4â€“5: Data fetch + signal generation (shared by all modes)\n",
    "- Cell 6: **Replay** â€” historical validation\n",
    "- Cell 7â€“8: **Shadow / Live** â€” daily trading workflow\n",
    "- Cell 9: Position monitoring & trade log export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a39873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All modules loaded\n",
      "   Signal mode: gated\n",
      "   Kalman: ON\n",
      "   OU Gate: ON\n",
      "   Entry threshold: 1.43\n",
      "   Exit threshold:  0.5\n",
      "   Stop loss: 0.1\n",
      "   Max hold:  20 days\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import sys, os, time, logging, importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure src/ is on the path\n",
    "src_dir = Path.cwd() if Path.cwd().name == 'src' else Path.cwd() / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# â”€â”€â”€ Existing strategy modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from strategy_config import ConfigLoader\n",
    "from strategies.mean_reversion import MeanReversionSignals, SignalConfig\n",
    "from backtest.engine import BacktestEngine, BacktestConfig\n",
    "\n",
    "# â”€â”€â”€ New Alpaca modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from connection.alpaca_connection import AlpacaConfig, AlpacaConnection, TradingMode\n",
    "from data.alpaca_data import AlpacaDataAdapter\n",
    "from execution.alpaca_executor import AlpacaExecutor, TradeDecision, TradeResult\n",
    "from execution.simulation import SimulationEngine\n",
    "\n",
    "# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ Load config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "config = ConfigLoader()\n",
    "signal_config = config.to_signal_config()\n",
    "bt_config = config.to_backtest_config()\n",
    "composite_weights = config.get_composite_weights()\n",
    "\n",
    "print(\"âœ… All modules loaded\")\n",
    "print(f\"   Signal mode: {signal_config.signal_mode}\")\n",
    "print(f\"   Kalman: {'ON' if signal_config.use_kalman else 'OFF'}\")\n",
    "print(f\"   OU Gate: {'ON' if signal_config.use_predicted_return else 'OFF'}\")\n",
    "print(f\"   Entry threshold: {bt_config.entry_threshold}\")\n",
    "print(f\"   Exit threshold:  {bt_config.exit_threshold}\")\n",
    "print(f\"   Stop loss: {bt_config.stop_loss_pct}\")\n",
    "print(f\"   Max hold:  {bt_config.max_holding_days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96201f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00:37 | connection.alpaca_connection | INFO | Trading client initialized (paper=True, mode=replay)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  ALPACA CONNECTION TEST\n",
      "============================================================\n",
      "  Status:          AccountStatus.ACTIVE\n",
      "  Mode:            PAPER\n",
      "  Trading Mode:    REPLAY\n",
      "  Cash:            $1,000,000.00\n",
      "  Buying Power:    $2,000,000.00\n",
      "  Portfolio Value: $1,000,000.00\n",
      "  Market Open:     False\n",
      "  Day Trades:      0\n",
      "  PDT Flag:        False\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ Trading mode: REPLAY\n",
      "   â†’ Using historical data only. No Alpaca API orders.\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 2: CONNECT TO ALPACA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Set trading mode here:\n",
    "#   TradingMode.REPLAY  â€” historical replay (no API calls for orders)\n",
    "#   TradingMode.SHADOW  â€” live data, simulated trades\n",
    "#   TradingMode.LIVE    â€” submit real paper-trade orders\n",
    "\n",
    "TRADING_MODE = TradingMode.REPLAY  # â† Change this as needed\n",
    "\n",
    "# Load API keys from .env and create connection\n",
    "alpaca_config = AlpacaConfig.from_env()\n",
    "alpaca_config.trading_mode = TRADING_MODE\n",
    "\n",
    "conn = AlpacaConnection(alpaca_config)\n",
    "conn.test_connection()\n",
    "\n",
    "print(f\"\\nğŸ”§ Trading mode: {TRADING_MODE.value.upper()}\")\n",
    "if TRADING_MODE == TradingMode.REPLAY:\n",
    "    print(\"   â†’ Using historical data only. No Alpaca API orders.\")\n",
    "elif TRADING_MODE == TradingMode.SHADOW:\n",
    "    print(\"   â†’ Live data, simulated trades. No real orders submitted.\")\n",
    "else:\n",
    "    print(\"   â†’ âš ï¸  LIVE MODE: Real paper-trade orders will be submitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bef2ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total curated universe: 269 symbols\n",
      "Computing Hurst exponents from local data...\n",
      "Computed Hurst for 208 mean-reverting symbols\n",
      "\n",
      "ğŸ“Š Trading Universe (30 symbols):\n",
      "   BBWI, KTOS, LUMN, FIVE, DUOL, NEOG, MPC, AFRM, CORT, CELH\n",
      "   CSX, NPO, BOOT, LPX, CVX, F, ATKR, FTDR, CRWD, DV\n",
      "   COP, TILE, PCVX, CARG, NSIT, PLAB, ASGN, PM, GTES, DY\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 3: SELECT TOP-30 UNIVERSE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Alpaca free tier: max 30 websocket symbols.\n",
    "# We pick the 30 best mean-reverters from our 216-symbol universe.\n",
    "# Criteria: lowest Hurst exponent â†’ strongest mean reversion.\n",
    "\n",
    "from data.universe_builder import SP500_CORE, NASDAQ_100_CORE, DOW_30, RUSSELL_2000_CORE\n",
    "\n",
    "# Combine all curated symbols (unique)\n",
    "all_symbols = sorted(set(SP500_CORE + NASDAQ_100_CORE + DOW_30 + RUSSELL_2000_CORE))\n",
    "print(f\"Total curated universe: {len(all_symbols)} symbols\")\n",
    "\n",
    "# â”€â”€ Option A: Use cached Hurst data from backtest (fast) â”€â”€\n",
    "# If you've already run the backtest notebook, load the parquet snapshots\n",
    "hurst_cache = Path('../data/snapshots/hurst_rankings.csv')\n",
    "if hurst_cache.exists():\n",
    "    hurst_df = pd.read_csv(hurst_cache)\n",
    "    top30 = hurst_df.nsmallest(30, 'hurst_exponent')['symbol'].tolist()\n",
    "    print(f\"Loaded cached Hurst rankings â†’ top 30 selected\")\n",
    "else:\n",
    "    # â”€â”€ Option B: Compute Hurst from locally cached historical data â”€â”€\n",
    "    daily_dir = Path('../data/historical/daily')\n",
    "    if daily_dir.exists() and list(daily_dir.glob('*.parquet')):\n",
    "        print(\"Computing Hurst exponents from local data...\")\n",
    "        signal_gen = MeanReversionSignals(signal_config)\n",
    "        hurst_results = {}\n",
    "\n",
    "        for pf in sorted(daily_dir.glob('*.parquet')):\n",
    "            sym = pf.stem\n",
    "            try:\n",
    "                df = pd.read_parquet(pf)\n",
    "                prices = df['close'] if 'close' in df.columns else df.iloc[:, 0]\n",
    "                if len(prices) >= 100:\n",
    "                    h = signal_gen.calculate_hurst_exponent(prices)\n",
    "                    if h is not None and h < 0.5:\n",
    "                        hurst_results[sym] = h\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if hurst_results:\n",
    "            ranked = sorted(hurst_results.items(), key=lambda x: x[1])\n",
    "            top30 = [s for s, _ in ranked[:30]]\n",
    "            print(f\"Computed Hurst for {len(hurst_results)} mean-reverting symbols\")\n",
    "        else:\n",
    "            # Fallback: diversified default selection\n",
    "            top30 = DOW_30[:30]\n",
    "            print(\"âš ï¸  No Hurst data available â€” falling back to DOW 30\")\n",
    "    else:\n",
    "        top30 = DOW_30[:30]\n",
    "        print(\"âš ï¸  No local data â€” falling back to DOW 30\")\n",
    "\n",
    "UNIVERSE = top30\n",
    "print(f\"\\nğŸ“Š Trading Universe ({len(UNIVERSE)} symbols):\")\n",
    "for i in range(0, len(UNIVERSE), 10):\n",
    "    print(f\"   {', '.join(UNIVERSE[i:i+10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710d0e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00:44 | connection.alpaca_connection | INFO | Data client initialized\n",
      "00:00:44 | data.alpaca_data | INFO | Loaded 30 symbols from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 30 symbols (up to 1825 cal days)...\n",
      "Data feed: IEX\n",
      "Cache dir: ../data/snapshots/alpaca_cache\n",
      "\n",
      "   ğŸ“¦ Cache hit: 30 symbols (latest: 2026-02-13, 4d ago, 1 trading day(s) to fetch)\n",
      "   ğŸ”„ Incremental update: 30 symbols from 2026-02-14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00:44 | data.alpaca_data | INFO | Fetched data for 0/30 symbols\n",
      "00:00:44 | data.alpaca_data | INFO | Pipeline data: 344 days Ã— 30 symbols (2024-10-01 to 2026-02-13)\n",
      "00:00:44 | data.alpaca_data | INFO | Cached 30 symbols to ../data/snapshots/alpaca_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Updated 0 symbols in 0.4s\n",
      "\n",
      "âœ… Data ready in 0.5s\n",
      "   Date range : 2024-10-01 â†’ 2026-02-13\n",
      "   Trading days: 344  (~1.4 years)\n",
      "   Symbols OK  : 30\n",
      "   Missing     : none\n",
      "   ğŸ’¾ Cache saved â†’ next run will be near-instant\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 4: FETCH DATA â€” CACHE-FIRST + SMART INCREMENTAL UPDATE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Performance strategy:\n",
    "#   1. Load cached parquet files from disk (< 1s for 30 symbols)\n",
    "#   2. Check trading calendar â€” skip API on weekends/holidays\n",
    "#   3. Fetch only NEW trading days since last cache date\n",
    "#   4. Skip symbols with no IEX coverage (tracked automatically)\n",
    "#   5. If no cache exists, full API fetch (first run only)\n",
    "#\n",
    "# Typical: <2s on weekends/holidays, 3-5s on next trading day.\n",
    "\n",
    "LOOKBACK_DAYS = 1825  # ~10 years â€” Alpaca returns whatever is available\n",
    "\n",
    "adapter = AlpacaDataAdapter(\n",
    "    data_client=conn.data_client,\n",
    "    data_feed=alpaca_config.data_feed,\n",
    "    cache_dir=Path('../data/snapshots/alpaca_cache'),\n",
    ")\n",
    "\n",
    "print(f\"Loading data for {len(UNIVERSE)} symbols (up to {LOOKBACK_DAYS} cal days)...\")\n",
    "print(f\"Data feed: {alpaca_config.data_feed.upper()}\")\n",
    "print(f\"Cache dir: {adapter.cache_dir}\\n\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "price_df, volume_df, raw_bars = adapter.fetch_pipeline_data(\n",
    "    symbols=UNIVERSE,\n",
    "    lookback_days=LOOKBACK_DAYS,\n",
    "    use_cache=True,\n",
    "    verbose=True,\n",
    ")\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "trading_days = len(price_df)\n",
    "trading_years = trading_days / 252\n",
    "\n",
    "print(f\"\\nâœ… Data ready in {elapsed:.1f}s\")\n",
    "print(f\"   Date range : {price_df.index.min().date()} â†’ {price_df.index.max().date()}\")\n",
    "print(f\"   Trading days: {trading_days}  (~{trading_years:.1f} years)\")\n",
    "print(f\"   Symbols OK  : {len(price_df.columns)}\")\n",
    "missing = set(UNIVERSE) - set(price_df.columns)\n",
    "if missing:\n",
    "    print(f\"   Missing     : {', '.join(sorted(missing))}\")\n",
    "    if adapter._no_data_symbols:\n",
    "        print(f\"   âš ï¸  No IEX data: {', '.join(sorted(adapter._no_data_symbols & set(UNIVERSE)))}\")\n",
    "        print(f\"      (These need SIP feed or are delisted â€” excluded automatically)\")\n",
    "else:\n",
    "    print(f\"   Missing     : none\")\n",
    "\n",
    "# Update universe to only symbols with valid data\n",
    "UNIVERSE = list(price_df.columns)\n",
    "\n",
    "# Save/update cache for next run\n",
    "adapter.save_cache(raw_bars, label='latest')\n",
    "print(f\"   ğŸ’¾ Cache saved â†’ next run will be near-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating signals for 30 symbols...\n",
      "  Weights: {'bollinger': 0.0, 'rsi_divergence': 0.75, 'rsi_level': 0.0}\n",
      "  Mode: gated | Gate: rsi_divergence\n",
      "\n",
      "  Processed 10/30...\n",
      "  Processed 20/30...\n",
      "  Processed 30/30...\n",
      "\n",
      "âœ… Signals generated for 30 symbols in 0.4s\n",
      "\n",
      "ğŸ“¡ Latest signals (2026-02-13):\n",
      "   Strong longs  (signal < -1.43): 0\n",
      "   Strong shorts (signal > +1.43): 0\n",
      "   Signal range: [0.00, 0.00]\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 5: GENERATE SIGNALS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Same signal pipeline as the backtest notebook.\n",
    "# Generates composite + individual signals for all symbols.\n",
    "\n",
    "signal_gen = MeanReversionSignals(signal_config)\n",
    "\n",
    "print(f\"Generating signals for {len(UNIVERSE)} symbols...\")\n",
    "print(f\"  Weights: {composite_weights}\")\n",
    "print(f\"  Mode: {signal_config.signal_mode} | Gate: {signal_config.gate_signal}\\n\")\n",
    "\n",
    "all_signals = {}\n",
    "all_individual_signals = {}\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "for i, symbol in enumerate(UNIVERSE):\n",
    "    if symbol in price_df.columns and symbol in volume_df.columns:\n",
    "        prices = price_df[symbol].dropna()\n",
    "        volumes = volume_df[symbol].dropna()\n",
    "\n",
    "        if len(prices) < 100:\n",
    "            continue\n",
    "\n",
    "        composite, individual = signal_gen.generate_composite_signal(\n",
    "            prices, volumes, weights=composite_weights\n",
    "        )\n",
    "        all_signals[symbol] = composite\n",
    "        all_individual_signals[symbol] = individual\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(UNIVERSE)}...\")\n",
    "\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"\\nâœ… Signals generated for {len(all_signals)} symbols in {elapsed:.1f}s\")\n",
    "\n",
    "# Build DataFrames matching backtest format\n",
    "signal_df = pd.DataFrame(all_signals)\n",
    "zscore_df = pd.DataFrame({\n",
    "    symbol: sigs['zscore']\n",
    "    for symbol, sigs in all_individual_signals.items()\n",
    "    if 'zscore' in sigs\n",
    "})\n",
    "\n",
    "# Align all data to common index\n",
    "common_idx = price_df.index.intersection(signal_df.index)\n",
    "price_df = price_df.loc[common_idx, signal_df.columns]\n",
    "volume_df = volume_df.loc[common_idx, signal_df.columns]\n",
    "signal_df = signal_df.loc[common_idx]\n",
    "zscore_df = zscore_df.loc[common_idx]\n",
    "\n",
    "# Show today's signals snapshot\n",
    "latest_date = signal_df.index[-1]\n",
    "latest_signals = signal_df.loc[latest_date].dropna().sort_values()\n",
    "print(f\"\\nğŸ“¡ Latest signals ({latest_date.date()}):\")\n",
    "print(f\"   Strong longs  (signal < -{bt_config.entry_threshold}): \"\n",
    "      f\"{(latest_signals < -bt_config.entry_threshold).sum()}\")\n",
    "print(f\"   Strong shorts (signal > +{bt_config.entry_threshold}): \"\n",
    "      f\"{(latest_signals > bt_config.entry_threshold).sum()}\")\n",
    "print(f\"   Signal range: [{latest_signals.min():.2f}, {latest_signals.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f529b",
   "metadata": {},
   "source": [
    "## Mode A: Historical Replay\n",
    "\n",
    "Replays historical data day-by-day through the live pipeline. Validates that the live execution system produces the same signals and trades as the backtest engine. Run this once before trusting the live system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96867bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Running replay: 2024-10-01 â†’ 2026-02-13\n",
      "   Capital: $100,000\n",
      "   Commission: 0.10% | Slippage: 0.05%\n",
      "\n",
      "\n",
      "============================================================\n",
      "  HISTORICAL REPLAY\n",
      "  Period: 2024-10-01 â†’ 2026-02-13 (344 days)\n",
      "  Universe: 30 symbols\n",
      "  Initial Capital: $100,000\n",
      "============================================================\n",
      "\n",
      "  Day 250/344 | 2025-09-30 | Equity: $145,256 (+45.3%) | Positions: 0 | Trades: 82\n",
      "\n",
      "============================================================\n",
      "  SIMULATION RESULTS\n",
      "============================================================\n",
      "  Final Equity:    $159,710.87\n",
      "  Total Return:    +59.71%\n",
      "  Sharpe Ratio:    0.86\n",
      "  Max Drawdown:    -48.99%\n",
      "  Total Trades:    111\n",
      "  Win Rate:        99.1%\n",
      "  Avg Trade P&L:   +5.50%\n",
      "  Avg Winner:      +5.61%\n",
      "  Avg Loser:       -6.70%\n",
      "  Open Positions:  0\n",
      "============================================================\n",
      "\n",
      "â±ï¸  Replay completed in 0.3s\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 6: HISTORICAL REPLAY â€” MAXIMUM WINDOW\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Replays the full signal_df day-by-day through the execution pipeline.\n",
    "# Uses ALL available signal days (after warmup) for maximum coverage.\n",
    "# Then compares against the backtest engine for consistency validation.\n",
    "\n",
    "# Create executor in REPLAY mode\n",
    "replay_config = AlpacaConfig.from_env()\n",
    "replay_config.trading_mode = TradingMode.REPLAY\n",
    "replay_conn = AlpacaConnection(replay_config)\n",
    "\n",
    "replay_executor = AlpacaExecutor(\n",
    "    connection=replay_conn,\n",
    "    commission_pct=bt_config.commission_pct,\n",
    "    max_position_pct=bt_config.max_position_size,\n",
    "    max_total_exposure=bt_config.max_total_exposure,\n",
    ")\n",
    "\n",
    "sim = SimulationEngine(\n",
    "    executor=replay_executor,\n",
    "    initial_capital=bt_config.initial_capital,\n",
    "    commission_pct=bt_config.commission_pct,\n",
    "    slippage_pct=bt_config.slippage_pct,\n",
    ")\n",
    "\n",
    "# â”€â”€ Use ALL available data (skip first 252 days for signal warmup) â”€â”€\n",
    "WARMUP_DAYS = 252  # 1 year warmup for signal generation\n",
    "if len(signal_df) > WARMUP_DAYS:\n",
    "    replay_start = signal_df.index[WARMUP_DAYS]\n",
    "else:\n",
    "    replay_start = signal_df.index[0]\n",
    "replay_end = signal_df.index[-1]\n",
    "\n",
    "replay_trading_days = len(signal_df.loc[replay_start:replay_end])\n",
    "replay_years = replay_trading_days / 252\n",
    "\n",
    "print(f\"ğŸ”„ Running replay over MAXIMUM available window:\")\n",
    "print(f\"   Period     : {replay_start.date()} â†’ {replay_end.date()}\")\n",
    "print(f\"   Days       : {replay_trading_days}  (~{replay_years:.1f} years)\")\n",
    "print(f\"   Warmup skip: first {WARMUP_DAYS} signal days\")\n",
    "print(f\"   Capital    : ${bt_config.initial_capital:,.0f}\")\n",
    "print(f\"   Commission : {bt_config.commission_pct:.2%} | Slippage: {bt_config.slippage_pct:.2%}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "replay_results = sim.run_replay(\n",
    "    price_df=price_df,\n",
    "    signal_df=signal_df,\n",
    "    volume_df=volume_df,\n",
    "    exit_signal_df=zscore_df,\n",
    "    config=bt_config,\n",
    "    start_date=replay_start,\n",
    "    end_date=replay_end,\n",
    "    verbose=True,\n",
    ")\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"\\nâ±ï¸  Replay completed in {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backtest on same period for comparison...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'total_return'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m bt_engine = BacktestEngine(bt_config)\n\u001b[32m      9\u001b[39m bt_results = bt_engine.run_backtest(\n\u001b[32m     10\u001b[39m     price_df.loc[replay_start:],\n\u001b[32m     11\u001b[39m     signal_df.loc[replay_start:],\n\u001b[32m     12\u001b[39m     volume_df.loc[replay_start:],\n\u001b[32m     13\u001b[39m     exit_signal_data=zscore_df.loc[replay_start:],\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Backtest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbt_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtotal_return\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compare equity curves\u001b[39;00m\n\u001b[32m     19\u001b[39m replay_equity = replay_results[\u001b[33m'\u001b[39m\u001b[33mequity_curve\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'total_return'"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 7: DETAILED REPLAY vs BACKTEST COMPARISON\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Runs the same period through BacktestEngine, then prints a comprehensive\n",
    "# side-by-side numerical comparison with the replay simulation.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Running backtest on same period for comparison...\\n\")\n",
    "\n",
    "bt_engine = BacktestEngine(bt_config)\n",
    "bt_results = bt_engine.run_backtest(\n",
    "    price_df.loc[replay_start:],\n",
    "    signal_df.loc[replay_start:],\n",
    "    volume_df.loc[replay_start:],\n",
    "    exit_signal_data=zscore_df.loc[replay_start:],\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ Replay metrics (from simulation dict) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "r = replay_results   # shorthand\n",
    "\n",
    "# â”€â”€â”€ Backtest metrics (from BacktestResults object) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "bt = bt_results\n",
    "\n",
    "# â”€â”€â”€ SIDE-BY-SIDE TABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"{'â•'*72}\")\n",
    "print(f\"  {'METRIC':<30s} {'REPLAY (Live Pipe)':>18s}  {'BACKTEST':>18s}\")\n",
    "print(f\"{'â•'*72}\")\n",
    "\n",
    "rows = [\n",
    "    (\"Period\",\n",
    "     f\"{replay_start.date()} â†’ {replay_end.date()}\",\n",
    "     f\"{replay_start.date()} â†’ {replay_end.date()}\"),\n",
    "    (\"Trading Days\",\n",
    "     f\"{len(r['equity_curve'])}\",\n",
    "     f\"{len(bt.equity_curve)}\"),\n",
    "    (\"â”€â”€â”€ Returns â”€â”€â”€\", \"\", \"\"),\n",
    "    (\"Total Return\",\n",
    "     f\"{r['total_return_pct']:+.2f}%\",\n",
    "     f\"{bt.total_return*100:+.2f}%\"),\n",
    "    (\"Annualized Return\",\n",
    "     f\"{(((1 + r['total_return_pct']/100) ** (252/max(len(r['equity_curve']),1))) - 1)*100:+.2f}%\",\n",
    "     f\"{bt.annualized_return*100:+.2f}%\"),\n",
    "    (\"Final Equity\",\n",
    "     f\"${r['final_equity']:,.2f}\",\n",
    "     f\"${bt.equity_curve.iloc[-1]:,.2f}\"),\n",
    "    (\"â”€â”€â”€ Risk â”€â”€â”€\", \"\", \"\"),\n",
    "    (\"Sharpe Ratio\",\n",
    "     f\"{r['sharpe_ratio']:.3f}\",\n",
    "     f\"{bt.sharpe_ratio:.3f}\"),\n",
    "    (\"Sortino Ratio\",\n",
    "     \"n/a\",\n",
    "     f\"{bt.sortino_ratio:.3f}\"),\n",
    "    (\"Calmar Ratio\",\n",
    "     \"n/a\",\n",
    "     f\"{bt.calmar_ratio:.3f}\"),\n",
    "    (\"Max Drawdown\",\n",
    "     f\"{r['max_drawdown_pct']:.2f}%\",\n",
    "     f\"{bt.max_drawdown*100:.2f}%\"),\n",
    "    (\"Max DD Duration\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.max_drawdown_duration} days\"),\n",
    "    (\"â”€â”€â”€ Trades â”€â”€â”€\", \"\", \"\"),\n",
    "    (\"Total Trades\",\n",
    "     f\"{r['total_trades']}\",\n",
    "     f\"{bt.total_trades}\"),\n",
    "    (\"Win Rate\",\n",
    "     f\"{r['win_rate']:.1f}%\",\n",
    "     f\"{bt.win_rate*100:.1f}%\"),\n",
    "    (\"Avg Trade P&L\",\n",
    "     f\"{r['avg_pnl_pct']:+.3f}%\",\n",
    "     f\"â€”\"),\n",
    "    (\"Avg Winner\",\n",
    "     f\"{r['avg_win_pct']:+.3f}%\",\n",
    "     f\"{bt.avg_win*100:+.3f}%\"),\n",
    "    (\"Avg Loser\",\n",
    "     f\"{r['avg_loss_pct']:+.3f}%\",\n",
    "     f\"{bt.avg_loss*100:+.3f}%\"),\n",
    "    (\"Profit Factor\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.profit_factor:.2f}\"),\n",
    "    (\"EV Per Trade\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.ev_per_trade*100:.3f}%\"),\n",
    "    (\"Avg Holding Days\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.avg_holding_days:.1f}\"),\n",
    "    (\"â”€â”€â”€ Exposure â”€â”€â”€\", \"\", \"\"),\n",
    "    (\"Avg Exposure\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.avg_exposure*100:.1f}%\"),\n",
    "    (\"Max Positions\",\n",
    "     \"â€”\",\n",
    "     f\"{bt.max_positions}\"),\n",
    "    (\"Open Positions (end)\",\n",
    "     f\"{r['open_positions']}\",\n",
    "     \"â€”\"),\n",
    "    (\"Total Commission\",\n",
    "     \"â€”\",\n",
    "     f\"${bt.total_commission:,.2f}\"),\n",
    "]\n",
    "\n",
    "for label, val_r, val_bt in rows:\n",
    "    if label.startswith(\"â”€â”€â”€\"):\n",
    "        print(f\"  {label:<30s}\")\n",
    "    else:\n",
    "        print(f\"  {label:<30s} {val_r:>18s}  {val_bt:>18s}\")\n",
    "\n",
    "print(f\"{'â•'*72}\")\n",
    "\n",
    "# â”€â”€â”€ REPLAY TRADE BREAKDOWN (if trades exist) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if r.get('trades_df') is not None and len(r['trades_df']) > 0:\n",
    "    tdf = r['trades_df']\n",
    "    print(f\"\\nğŸ“‹ Replay Trade Breakdown:\")\n",
    "    print(f\"   Long trades : {(tdf['side']=='long').sum()}\")\n",
    "    print(f\"   Short trades: {(tdf['side']=='short').sum()}\")\n",
    "    if 'holding_days' in tdf.columns:\n",
    "        print(f\"   Avg holding  : {tdf['holding_days'].mean():.1f} days\")\n",
    "        print(f\"   Med holding  : {tdf['holding_days'].median():.0f} days\")\n",
    "    print(f\"   Best trade   : {tdf['pnl_pct'].max()*100:+.2f}%  ({tdf.loc[tdf['pnl_pct'].idxmax(), 'symbol']})\")\n",
    "    print(f\"   Worst trade  : {tdf['pnl_pct'].min()*100:+.2f}%  ({tdf.loc[tdf['pnl_pct'].idxmin(), 'symbol']})\")\n",
    "    print(f\"   Total P&L $  : ${tdf['pnl'].sum():,.2f}\")\n",
    "    print(f\"   Commission $ : ${tdf['commission'].sum():,.2f}\")\n",
    "\n",
    "    # Monthly returns\n",
    "    eq = r['equity_curve']\n",
    "    monthly = eq.resample('ME').last().pct_change().dropna() * 100\n",
    "    if len(monthly) > 0:\n",
    "        print(f\"\\nğŸ“… Monthly Return Stats (Replay):\")\n",
    "        print(f\"   Mean     : {monthly.mean():+.2f}%\")\n",
    "        print(f\"   Median   : {monthly.median():+.2f}%\")\n",
    "        print(f\"   Std Dev  : {monthly.std():.2f}%\")\n",
    "        print(f\"   Best mo  : {monthly.max():+.2f}%\")\n",
    "        print(f\"   Worst mo : {monthly.min():+.2f}%\")\n",
    "        print(f\"   Positive : {(monthly > 0).sum()}/{len(monthly)} months\")\n",
    "\n",
    "# â”€â”€â”€ EQUITY CURVE COMPARISON (chart) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "replay_equity = r['equity_curve']\n",
    "bt_equity = bt.equity_curve\n",
    "\n",
    "comparison = sim.compare_with_backtest(\n",
    "    backtest_equity=bt_equity,\n",
    "    label_sim='Replay (Live Pipeline)',\n",
    "    label_bt='Backtest Engine',\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Alignment Metrics:\")\n",
    "print(f\"   Correlation       : {comparison['correlation']:.4f}\")\n",
    "print(f\"   Tracking Error    : {comparison['tracking_error_pct']:.2f}% (annualized)\")\n",
    "print(f\"   Max Deviation     : {comparison['max_deviation']:.2f}\")\n",
    "print(f\"   Avg Deviation     : {comparison['avg_deviation']:.2f}\")\n",
    "print(f\"   Overlapping Days  : {comparison['common_days']}\")\n",
    "\n",
    "if comparison['correlation'] > 0.95:\n",
    "    print(\"\\nâœ… Strong match! Live pipeline is consistent with backtest.\")\n",
    "elif comparison['correlation'] > 0.85:\n",
    "    print(\"\\nâš ï¸  Moderate match. Check for timing/sizing differences.\")\n",
    "else:\n",
    "    print(\"\\nâŒ Significant divergence â€” investigate before going live.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2720ff",
   "metadata": {},
   "source": [
    "## Mode B: Shadow / Live Daily Trading\n",
    "\n",
    "Run this section daily. In **Shadow mode**, it generates signals and tracks hypothetical trades without submitting orders. In **Live mode**, it submits real paper-trade orders to Alpaca.\n",
    "\n",
    "**Daily workflow:** Run cells 1â€“5 (setup + data + signals), then cell 8 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caca18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 8: DAILY SHADOW / LIVE EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Processes today's signals through the execution pipeline.\n",
    "# In SHADOW mode: logs hypothetical trades, tracks simulated P&L.\n",
    "# In LIVE mode: submits real orders to Alpaca paper trading.\n",
    "#\n",
    "# State persistence: shadow positions survive across runs via trade log CSV.\n",
    "\n",
    "# â”€â”€â”€ Initialize or restore shadow state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SHADOW_LOG = Path('../data/snapshots/shadow_state.csv')\n",
    "\n",
    "executor = AlpacaExecutor(\n",
    "    connection=conn,\n",
    "    commission_pct=0.0 if TRADING_MODE == TradingMode.LIVE else bt_config.commission_pct,\n",
    "    max_position_pct=bt_config.max_position_size,\n",
    "    max_total_exposure=bt_config.max_total_exposure,\n",
    ")\n",
    "\n",
    "shadow_sim = SimulationEngine(\n",
    "    executor=executor,\n",
    "    initial_capital=bt_config.initial_capital,\n",
    "    commission_pct=bt_config.commission_pct if TRADING_MODE != TradingMode.LIVE else 0.0,\n",
    "    slippage_pct=bt_config.slippage_pct if TRADING_MODE != TradingMode.LIVE else 0.0,\n",
    ")\n",
    "\n",
    "# Restore previous shadow positions if they exist\n",
    "if SHADOW_LOG.exists() and TRADING_MODE == TradingMode.SHADOW:\n",
    "    prev = pd.read_csv(SHADOW_LOG)\n",
    "    if not prev.empty:\n",
    "        for _, row in prev.iterrows():\n",
    "            from execution.simulation import SimulatedPosition\n",
    "            shadow_sim.positions[row['symbol']] = SimulatedPosition(\n",
    "                symbol=row['symbol'],\n",
    "                qty=int(row['qty']),\n",
    "                side=row['side'],\n",
    "                entry_price=float(row['entry_price']),\n",
    "                entry_date=pd.Timestamp(row['entry_date']),\n",
    "                signal_strength=float(row.get('signal_strength', 0)),\n",
    "                current_price=float(row.get('current_price', row['entry_price'])),\n",
    "            )\n",
    "        shadow_sim.cash -= sum(\n",
    "            p.entry_price * abs(p.qty) for p in shadow_sim.positions.values()\n",
    "            if p.side == 'long'\n",
    "        )\n",
    "        print(f\"â™»ï¸  Restored {len(shadow_sim.positions)} shadow positions\")\n",
    "\n",
    "# â”€â”€â”€ Process today â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "today = signal_df.index[-1]  # Latest date with signals\n",
    "print(f\"\\n{'â•'*60}\")\n",
    "print(f\"  DAILY EXECUTION â€” {today.date()} â€” {TRADING_MODE.value.upper()} MODE\")\n",
    "print(f\"{'â•'*60}\")\n",
    "\n",
    "if TRADING_MODE in (TradingMode.SHADOW, TradingMode.REPLAY):\n",
    "    # Shadow: process through simulation engine\n",
    "    shadow_sim.process_shadow_day(\n",
    "        date=today,\n",
    "        signal_df=signal_df,\n",
    "        price_df=price_df,\n",
    "        volume_df=volume_df,\n",
    "        exit_signal_df=zscore_df,\n",
    "        config=bt_config,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Save shadow state for next run\n",
    "    if shadow_sim.positions:\n",
    "        state_rows = []\n",
    "        for sym, pos in shadow_sim.positions.items():\n",
    "            state_rows.append({\n",
    "                'symbol': pos.symbol, 'qty': pos.qty, 'side': pos.side,\n",
    "                'entry_price': pos.entry_price, 'entry_date': pos.entry_date,\n",
    "                'signal_strength': pos.signal_strength,\n",
    "                'current_price': pos.current_price,\n",
    "            })\n",
    "        pd.DataFrame(state_rows).to_csv(SHADOW_LOG, index=False)\n",
    "        print(f\"\\nğŸ’¾ Shadow state saved ({len(state_rows)} positions)\")\n",
    "    else:\n",
    "        if SHADOW_LOG.exists():\n",
    "            SHADOW_LOG.unlink()\n",
    "        print(\"\\nğŸ’¾ No open positions â€” shadow state cleared\")\n",
    "\n",
    "else:\n",
    "    # LIVE mode: generate decisions and submit orders\n",
    "    current_positions = {}\n",
    "    for pos in conn.get_positions():\n",
    "        current_positions[pos['symbol']] = {\n",
    "            'qty': int(pos['qty']),\n",
    "            'side': 'long' if int(pos['qty']) > 0 else 'short',\n",
    "            'entry_price': float(pos['avg_entry_price']),\n",
    "            'entry_date': pd.Timestamp.now() - pd.Timedelta(days=1),  # Approximate\n",
    "        }\n",
    "\n",
    "    decisions = executor.generate_decisions_from_signals(\n",
    "        signal_df=signal_df,\n",
    "        price_df=price_df,\n",
    "        volume_df=volume_df,\n",
    "        exit_signal_df=zscore_df,\n",
    "        date=today,\n",
    "        current_positions=current_positions,\n",
    "        config=bt_config,\n",
    "    )\n",
    "\n",
    "    if decisions:\n",
    "        print(f\"\\nğŸ“‹ {len(decisions)} trade decisions:\")\n",
    "        for d in decisions:\n",
    "            print(f\"   {d.action.upper():6s} {d.symbol:6s} x{d.target_qty:4d}  \"\n",
    "                  f\"signal={d.signal_strength:+.3f}  {d.reason}\")\n",
    "\n",
    "        # Get current prices for execution\n",
    "        current_prices = adapter.get_latest_prices([d.symbol for d in decisions])\n",
    "        results = executor.execute_decisions(decisions, current_prices)\n",
    "\n",
    "        print(f\"\\nğŸ“Š Execution results:\")\n",
    "        for r in results:\n",
    "            status_icon = 'âœ…' if r.status in ('filled', 'submitted') else 'âŒ'\n",
    "            print(f\"   {status_icon} {r.decision.symbol} â†’ {r.status} \"\n",
    "                  f\"@ ${r.filled_price or 0:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nğŸ˜´ No trade signals today\")\n",
    "\n",
    "    # Show account summary\n",
    "    account = conn.get_account()\n",
    "    print(f\"\\nğŸ’° Account: ${account['portfolio_value']:,.2f} \"\n",
    "          f\"(cash: ${account['cash']:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d378c",
   "metadata": {},
   "source": [
    "## Monitoring & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 9: POSITION MONITORING DASHBOARD\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Shows current positions, P&L, and signal status across all modes.\n",
    "\n",
    "def show_dashboard(sim_engine=None, connection=None, mode=None):\n",
    "    \"\"\"Display position monitoring dashboard\"\"\"\n",
    "    print(f\"\\n{'â•'*70}\")\n",
    "    print(f\"  POSITION DASHBOARD â€” {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"{'â•'*70}\")\n",
    "\n",
    "    if mode in (TradingMode.SHADOW, TradingMode.REPLAY) and sim_engine:\n",
    "        # Shadow/Replay positions\n",
    "        print(f\"\\n  Mode: {mode.value.upper()} | Equity: ${sim_engine.equity:,.2f} \"\n",
    "              f\"| Cash: ${sim_engine.cash:,.2f}\")\n",
    "        print(f\"  Open positions: {len(sim_engine.positions)}\")\n",
    "        print(f\"  Completed trades: {len(sim_engine.completed_trades)}\")\n",
    "\n",
    "        if sim_engine.positions:\n",
    "            print(f\"\\n  {'Symbol':8s} {'Side':6s} {'Qty':>6s} {'Entry':>10s} \"\n",
    "                  f\"{'Current':>10s} {'P&L':>10s} {'P&L%':>8s} {'Days':>5s}\")\n",
    "            print(f\"  {'â”€'*65}\")\n",
    "\n",
    "            total_pnl = 0\n",
    "            for sym, pos in sorted(sim_engine.positions.items()):\n",
    "                days = (pd.Timestamp.now() - pos.entry_date).days\n",
    "                pnl = pos.unrealized_pnl\n",
    "                pnl_pct = pos.unrealized_pnl_pct * 100\n",
    "                total_pnl += pnl\n",
    "                icon = 'ğŸŸ¢' if pnl >= 0 else 'ğŸ”´'\n",
    "                print(f\"  {icon} {sym:6s} {pos.side:6s} {abs(pos.qty):6d} \"\n",
    "                      f\"${pos.entry_price:9.2f} ${pos.current_price:9.2f} \"\n",
    "                      f\"${pnl:9.2f} {pnl_pct:+7.2f}% {days:5d}\")\n",
    "            print(f\"  {'â”€'*65}\")\n",
    "            print(f\"  {'Total':55s} ${total_pnl:9.2f}\")\n",
    "\n",
    "        # Trade history summary\n",
    "        if sim_engine.completed_trades:\n",
    "            wins = sum(1 for t in sim_engine.completed_trades if t.pnl > 0)\n",
    "            losses = len(sim_engine.completed_trades) - wins\n",
    "            avg_pnl = np.mean([t.pnl_pct * 100 for t in sim_engine.completed_trades])\n",
    "            print(f\"\\n  Trade History: {wins}W / {losses}L | \"\n",
    "                  f\"Win rate: {wins/(wins+losses)*100:.1f}% | \"\n",
    "                  f\"Avg P&L: {avg_pnl:+.2f}%\")\n",
    "\n",
    "    elif mode == TradingMode.LIVE and connection:\n",
    "        # Live positions from Alpaca\n",
    "        account = connection.get_account()\n",
    "        positions = connection.get_positions()\n",
    "\n",
    "        print(f\"\\n  Equity: ${account['portfolio_value']:,.2f} | \"\n",
    "              f\"Cash: ${account['cash']:,.2f} | \"\n",
    "              f\"Day trades: {account['daytrade_count']}/3\")\n",
    "\n",
    "        if positions:\n",
    "            print(f\"\\n  {'Symbol':8s} {'Side':6s} {'Qty':>6s} {'Entry':>10s} \"\n",
    "                  f\"{'Current':>10s} {'P&L':>10s} {'P&L%':>8s}\")\n",
    "            print(f\"  {'â”€'*60}\")\n",
    "\n",
    "            for pos in positions:\n",
    "                qty = int(pos['qty'])\n",
    "                side = 'long' if qty > 0 else 'short'\n",
    "                entry = float(pos['avg_entry_price'])\n",
    "                current = float(pos['current_price'])\n",
    "                pnl = float(pos['unrealized_pl'])\n",
    "                pnl_pct = float(pos['unrealized_plpc']) * 100\n",
    "                icon = 'ğŸŸ¢' if pnl >= 0 else 'ğŸ”´'\n",
    "                print(f\"  {icon} {pos['symbol']:6s} {side:6s} {abs(qty):6d} \"\n",
    "                      f\"${entry:9.2f} ${current:9.2f} ${pnl:9.2f} {pnl_pct:+7.2f}%\")\n",
    "        else:\n",
    "            print(\"\\n  No open positions\")\n",
    "\n",
    "    # Show today's signals that hit thresholds\n",
    "    if 'signal_df' in dir() or 'signal_df' in globals():\n",
    "        latest = signal_df.iloc[-1].dropna()\n",
    "        entries = latest[latest.abs() > bt_config.entry_threshold].sort_values()\n",
    "        if len(entries) > 0:\n",
    "            print(f\"\\n  ğŸ“¡ Active entry signals ({len(entries)}):\")\n",
    "            for sym, val in entries.items():\n",
    "                direction = \"SHORT\" if val > 0 else \"LONG \"\n",
    "                print(f\"     {direction} {sym:6s}  signal={val:+.3f}\")\n",
    "\n",
    "\n",
    "# Run dashboard for the active mode\n",
    "active_sim = shadow_sim if 'shadow_sim' in dir() else (sim if 'sim' in dir() else None)\n",
    "show_dashboard(sim_engine=active_sim, connection=conn, mode=TRADING_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea10ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 10: EXPORT TRADE LOGS & EQUITY CURVES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "export_dir = Path('../data/snapshots/trading_logs')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# Export from whichever sim engine is active\n",
    "active = shadow_sim if 'shadow_sim' in dir() else (sim if 'sim' in dir() else None)\n",
    "\n",
    "if active and active.completed_trades:\n",
    "    trade_path = export_dir / f'trades_{TRADING_MODE.value}_{timestamp}.csv'\n",
    "    active.export_trade_log(trade_path)\n",
    "    print(f\"ğŸ“„ Trade log: {trade_path}\")\n",
    "\n",
    "if active and active.daily_snapshots:\n",
    "    equity_path = export_dir / f'equity_{TRADING_MODE.value}_{timestamp}.csv'\n",
    "    active.export_equity_curve(equity_path)\n",
    "    print(f\"ğŸ“ˆ Equity curve: {equity_path}\")\n",
    "\n",
    "    # Plot equity curve\n",
    "    snapshots_df = pd.DataFrame([\n",
    "        {'date': s.date, 'equity': s.equity, 'daily_pnl': s.daily_pnl,\n",
    "         'n_positions': s.n_positions, 'trades_entered': s.trades_entered,\n",
    "         'trades_exited': s.trades_exited}\n",
    "        for s in active.daily_snapshots\n",
    "    ])\n",
    "    snapshots_df.set_index('date', inplace=True)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "    # Equity\n",
    "    axes[0].plot(snapshots_df['equity'], linewidth=2, color='blue')\n",
    "    axes[0].set_ylabel('Equity ($)')\n",
    "    axes[0].set_title(f'Equity Curve â€” {TRADING_MODE.value.upper()} Mode')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    # Daily P&L\n",
    "    colors = ['green' if x >= 0 else 'red' for x in snapshots_df['daily_pnl']]\n",
    "    axes[1].bar(snapshots_df.index, snapshots_df['daily_pnl'], color=colors, alpha=0.7)\n",
    "    axes[1].set_ylabel('Daily P&L ($)')\n",
    "    axes[1].set_title('Daily P&L')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    # Position count\n",
    "    axes[2].fill_between(snapshots_df.index, 0, snapshots_df['n_positions'],\n",
    "                         alpha=0.5, color='purple')\n",
    "    axes[2].set_ylabel('Positions')\n",
    "    axes[2].set_title('Open Positions')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No trading data to export yet. Run replay or shadow mode first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
